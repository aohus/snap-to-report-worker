import os

import onnx
import torch
from onnx.external_data_helper import load_external_data_for_model
from onnxruntime.quantization import QuantType, quantize_dynamic
from onnxruntime.quantization.shape_inference import quant_pre_process


def convert_final_fixed():
    output_file = "cosplace_resnet50.onnx"
    preprocessed_file = "cosplace_resnet50_pre.onnx"
    quantized_file = "cosplace_resnet50_int8.onnx"

    # 1. PyTorch ëª¨ë¸ ë¡œë“œ
    print("1. ëª¨ë¸ ë¡œë“œ ì¤‘...")
    try:
        model = torch.hub.load("gmberton/CosPlace", "get_trained_model", backbone="ResNet50", fc_output_dim=512)
        model.eval().cpu()
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. ONNX Export (Opset 18)
    print("2. ONNX Export (Opset 18)...")
    dummy_input = torch.randn(1, 3, 480, 640)
    torch.onnx.export(
        model,
        dummy_input,
        output_file,
        export_params=True,
        opset_version=18,
        do_constant_folding=True,
        input_names=["input"],
        output_names=["output"],
        dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
    )
    print(f"-> Export ì™„ë£Œ: {output_file}")

    # [í•µì‹¬ ìˆ˜ì •] 2.5 ì™¸ë¶€ ë°ì´í„° í•©ì¹˜ê¸° (Monolithic ë³€í™˜)
    # .data íŒŒì¼ì´ ë”°ë¡œ ìƒê²¼ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë©”ëª¨ë¦¬ë¡œ ë¡œë“œí•´ì„œ íŒŒì¼ í•˜ë‚˜ë¡œ ë‹¤ì‹œ ì €ì¥í•©ë‹ˆë‹¤.
    print("2.5. íŒŒì¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (Merging external data)...")
    try:
        onnx_model = onnx.load(output_file)
        # ì™¸ë¶€ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë©”ëª¨ë¦¬ë¡œ ë¡œë“œ
        load_external_data_for_model(onnx_model, ".")
        # ë‹¤ì‹œ ì €ì¥ (ResNet50ì€ 2GBë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ í•˜ë‚˜ë¡œ í•©ì³ì§‘ë‹ˆë‹¤)
        onnx.save(onnx_model, output_file)
        print("-> ë³‘í•© ì™„ë£Œ. ì´ì œ ì•ˆì „í•˜ê²Œ ì „ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ë³‘í•© ê³¼ì • ê²½ê³  (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    # 3. Pre-processing
    print("3. Pre-processing (Optimizing)...")
    try:
        quant_pre_process(
            input_model_path=output_file,
            output_model_path=preprocessed_file,
            skip_symbolic_shape=True,  # ì´ì „ì— ë°œìƒí•œ NoneType ì—ëŸ¬ ë°©ì§€
        )
        print(f"-> ì „ì²˜ë¦¬ ì™„ë£Œ: {preprocessed_file}")
    except Exception as e:
        print(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        print("-> ì›ë³¸ íŒŒì¼ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        preprocessed_file = output_file

    # 3.5. Shape Info ì œê±° (ì¶©ëŒ ë°©ì§€)
    # quant_pre_process í›„ Shape ì •ë³´ê°€ ê¼¬ì—¬ì„œ quantize_dynamicì—ì„œ ì—ëŸ¬ê°€ ë‚˜ëŠ” ê²½ìš°ê°€ ë§ìŒ
    # ë”°ë¼ì„œ ëª…ì‹œì ì¸ Shape ì •ë³´ë¥¼ ë‚ ë¦¬ê³  ë‹¤ì‹œ ì¶”ë¡ í•˜ê²Œ í•¨
    print("3.5. Shape Info ì œê±° (ì¶©ëŒ ë°©ì§€)...")
    try:
        m = onnx.load(preprocessed_file)
        if len(m.graph.value_info) > 0:
            print(f"-> ê¸°ì¡´ value_info {len(m.graph.value_info)}ê°œ ì œê±°")
            del m.graph.value_info[:]
            onnx.save(m, preprocessed_file)
    except Exception as e:
        print(f"Shape ì œê±° ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

    # 4. INT8 ì–‘ìí™”
    print("4. INT8 ì–‘ìí™”...")
    try:
        quantize_dynamic(model_input=preprocessed_file, model_output=quantized_file, weight_type=QuantType.QUInt8)
        print(f"\nğŸ‰ ì„±ê³µ! ìµœì¢… íŒŒì¼: {quantized_file}")
    except Exception as e:
        print(f"ì–‘ìí™” ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    convert_final_fixed()
