#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
deep_cluster.py

Stage 2~5 êµ¬í˜„:

- Stage 2: ì „ì—­ ì„ë² ë”© ì¶”ì¶œ (place-recognition ìš©ë„)
- Stage 3: SIFT + RANSAC ë¡œ ê¸°í•˜ ê²€ì¦
- Stage 4: k-NN + ì—°ê²°ìš”ì†Œ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
- Stage 5: ê° í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì‹œê°„ ìˆœ ì •ë ¬ (ì „/ì¤‘/í›„ ë“± í›„ì²˜ë¦¬ìš©)

ì‚¬ìš© ì˜ˆ:
    from deep_cluster import DeepCluster, PhotoMeta

    photos = [
        PhotoMeta(id=1, path="/path/a.jpg", timestamp=...),
        PhotoMeta(id=2, path="/path/b.jpg", timestamp=...),
        ...
    ]
    clusterer = DeepCluster()
    clusters = clusterer.cluster(photos)
"""

from __future__ import annotations

import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import numpy as np
from domain.extractors.APGeM_extractor import APGeMDescriptorExtractor
from domain.photometa import PhotoMeta
from sklearn.neighbors import NearestNeighbors

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)


# -------------------------------------------------------------------
# ë¡œì»¬ íŠ¹ì§• + RANSAC ê¸°ë°˜ ê¸°í•˜ ê²€ì¦
# -------------------------------------------------------------------

try:
    import cv2  # type: ignore
except Exception:  # pragma: no cover
    cv2 = None  # type: ignore


class LocalGeometryMatcher:
    """
    ë‘ ì´ë¯¸ì§€ê°€ 'ì •ë§ ê°™ì€ ì¥ë©´'ì¸ì§€ íŒë‹¨í•˜ê¸° ìœ„í•œ ê¸°í•˜ ê²€ì¦ê¸°.
    SIFT + Lowe ratio test + RANSAC (homography ë˜ëŠ” fundamental matrix) ì‚¬ìš©.
    """

    def __init__(
        self,
        max_features: int = 1500,
        ratio_thresh: float = 0.75,
        ransac_reproj_thresh: float = 5.0,
        min_good_matches: int = 15,
    ) -> None:
        self.max_features = max_features
        self.ratio_thresh = ratio_thresh
        self.ransac_reproj_thresh = ransac_reproj_thresh
        self.min_good_matches = min_good_matches

        if cv2 is None:
            logger.warning(
                "âš ï¸ OpenCV(cv2)ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. "
                "ê¸°í•˜ ê²€ì¦ ë‹¨ê³„ëŠ” í•­ìƒ score=1.0 ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
            )
            self.enabled = False
            self.detector = None
        else:
            self.enabled = True
            # SIFT ë˜ëŠ” AKAZE ë“±ìœ¼ë¡œ êµì²´ ê°€ëŠ¥
            try:
                self.detector = cv2.SIFT_create(nfeatures=self.max_features)  # type: ignore[attr-defined]
            except Exception:
                logger.warning(
                    "âš ï¸ SIFT ìƒì„± ì‹¤íŒ¨. opencv-contrib-python ì´ í•„ìš”í•©ë‹ˆë‹¤. "
                    "ê¸°í•˜ ê²€ì¦ ë‹¨ê³„ëŠ” ë¹„í™œì„±í™”ë©ë‹ˆë‹¤."
                )
                self.detector = None
                self.enabled = False

    def _load_gray(self, path: Path) -> Optional[np.ndarray]:
        if not self.enabled or self.detector is None:
            return None
        img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)  # type: ignore[attr-defined]
        if img is None:
            logger.warning(f"âš ï¸ Failed to read image for geometry: {path}")
            return None
        return img

    def geo_score(self, path1: Path, path2: Path) -> float:
        """
        0.0 ~ 1.0 ì‚¬ì´ì˜ ê¸°í•˜í•™ì  ì¼ê´€ì„± ì ìˆ˜.
        - 0.0 ì— ê°€ê¹Œìš¸ìˆ˜ë¡ êµ¬ì¡°ê°€ ë‹¤ë¥´ê±°ë‚˜ ë§¤ì¹­ ì‹¤íŒ¨
        - 1.0 ì— ê°€ê¹Œìš¸ìˆ˜ë¡ êµ¬ì¡°ê°€ ìƒë‹¹íˆ ì¼ì¹˜

        ê¸°í•˜ ê²€ì¦ì„ ì‚¬ìš©í•˜ì§€ ëª»í•˜ëŠ” í™˜ê²½(cv2 ì—†ìŒ ë“±)ì—ì„œëŠ” í•­ìƒ 1.0 ë°˜í™˜.
        """
        if not self.enabled or self.detector is None:
            return 1.0  # fallback: ê¸°í•˜ ê²€ì¦ì„ ìƒëµí•˜ê³  í•­ìƒ í†µê³¼

        img1 = self._load_gray(path1)
        img2 = self._load_gray(path2)
        if img1 is None or img2 is None:
            return 0.0

        keypoints1, desc1 = self.detector.detectAndCompute(img1, None)
        keypoints2, desc2 = self.detector.detectAndCompute(img2, None)
        if desc1 is None or desc2 is None:
            return 0.0

        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)  # type: ignore[attr-defined]
        matches = bf.knnMatch(desc1, desc2, k=2)  # type: ignore[attr-defined]

        good = []
        for m, n in matches:
            if m.distance < self.ratio_thresh * n.distance:
                good.append(m)

        if len(good) < self.min_good_matches:
            return 0.0

        pts1 = np.float32([keypoints1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
        pts2 = np.float32([keypoints2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)

        # Homography + RANSAC
        H, mask = cv2.findHomography(  # type: ignore[attr-defined]
            pts1,
            pts2,
            cv2.RANSAC,
            ransacReprojThreshold=self.ransac_reproj_thresh,  # type: ignore[attr-defined]
        )
        if H is None or mask is None:
            return 0.0

        inliers = int(mask.ravel().sum())
        total = len(good)
        if total == 0:
            return 0.0
        score = float(inliers) / float(total)
        return max(0.0, min(1.0, score))


# -------------------------------------------------------------------
# ì—°ê²°ìš”ì†Œ (Union-Find)
# -------------------------------------------------------------------

class UnionFind:
    def __init__(self, n: int) -> None:
        self.parent = list(range(n))
        self.rank = [0] * n

    def find(self, x: int) -> int:
        while self.parent[x] != x:
            self.parent[x] = self.parent[self.parent[x]]
            x = self.parent[x]
        return x

    def union(self, a: int, b: int) -> None:
        ra, rb = self.find(a), self.find(b)
        if ra == rb:
            return
        if self.rank[ra] < self.rank[rb]:
            self.parent[ra] = rb
        elif self.rank[ra] > self.rank[rb]:
            self.parent[rb] = ra
        else:
            self.parent[rb] = ra
            self.rank[ra] += 1

    def to_labels(self) -> List[int]:
        roots = [self.find(i) for i in range(len(self.parent))]
        root_to_label: Dict[int, int] = {}
        labels: List[int] = []
        next_label = 0
        for r in roots:
            if r not in root_to_label:
                root_to_label[r] = next_label
                next_label += 1
            labels.append(root_to_label[r])
        return labels


# -------------------------------------------------------------------
# DeepCluster
# -------------------------------------------------------------------

class DeepCluster:
    """
    Stage 2~5 í´ëŸ¬ìŠ¤í„°ë§ êµ¬í˜„.

    - ì…ë ¥: ë™ì¼ GPS í´ëŸ¬ìŠ¤í„°(ë˜ëŠ” job ë‹¨ìœ„)ë¡œ ë¬¶ì¸ PhotoMeta ë¦¬ìŠ¤íŠ¸
    - ì¶œë ¥: PhotoMeta ì˜ ë¦¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (ê° ë¦¬ìŠ¤íŠ¸ = ê°™ì€ ì¥ë©´ í´ëŸ¬ìŠ¤í„°)

    interface requirement:
        def cluster(self, photos: Sequence[PhotoMeta]) -> List[List[PhotoMeta]]
    """

    def __init__(
        self,
        descriptor_extractor: Optional[APGeMDescriptorExtractor] = None,
        geo_matcher: Optional[LocalGeometryMatcher] = None,
        similarity_threshold: float = 0.7,
        geo_threshold: float = 0.25,
        min_cluster_size: int = 2,
        knn_k: int = 10,
    ) -> None:
        """
        Args:
            descriptor_extractor: ì „ì—­ ì„ë² ë”© ì¶”ì¶œê¸°. Noneì´ë©´ ê¸°ë³¸ CLIP extractor ì‚¬ìš©.
            geo_matcher: ê¸°í•˜ ê²€ì¦ê¸°. Noneì´ë©´ ê¸°ë³¸ LocalGeometryMatcher ì‚¬ìš©.
            similarity_threshold: ì „ì—­ ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„ê³„ê°’.
            geo_threshold: ê¸°í•˜ score ì„ê³„ê°’ (0~1).
            min_cluster_size: ì´ë³´ë‹¤ ì‘ì€ í´ëŸ¬ìŠ¤í„°ëŠ” ë²„ë¦¬ê±°ë‚˜ ë‹¨ë… ì²˜ë¦¬.
            knn_k: k-NN ê·¸ë˜í”„ì—ì„œ ì´ì›ƒ ê°œìˆ˜.
        """
        self.descriptor_extractor = (
            descriptor_extractor if descriptor_extractor is not None else APGeMDescriptorExtractor()
        )
        self.geo_matcher = geo_matcher if geo_matcher is not None else LocalGeometryMatcher()
        self.similarity_threshold = float(similarity_threshold)
        self.geo_threshold = float(geo_threshold)
        self.min_cluster_size = int(min_cluster_size)
        self.knn_k = int(knn_k)

    # ------------------------------------------------------------------
    # public interface
    # ------------------------------------------------------------------
    async def cluster(self, photos: Sequence[PhotoMeta]) -> List[List[PhotoMeta]]:
        """
        Stage 2~5 ì „ì²´ íŒŒì´í”„ë¼ì¸.

        1) ì „ì—­ ì„ë² ë”© ì¶”ì¶œ (Stage 2)
        2) k-NN ê·¸ë˜í”„ ìƒì„± (Stage 2)
        3) SIFT+RANSAC ê¸°í•˜ ê²€ì¦ìœ¼ë¡œ ê°„ì„  í•„í„°ë§ (Stage 3)
        4) Union-Findë¡œ ì—°ê²°ìš”ì†Œ â†’ í´ëŸ¬ìŠ¤í„° (Stage 4)
        5) ê° í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ë¥¼ ì´¬ì˜ ì‹œê° ìˆœìœ¼ë¡œ ì •ë ¬ (Stage 5)

        Returns:
            List[List[PhotoMeta]]: ê° ë‚´ë¶€ ë¦¬ìŠ¤íŠ¸ê°€ "ê°™ì€ ì¥ë©´" í´ëŸ¬ìŠ¤í„°.
        """
        if not photos:
            return []

        logger.info(f"ğŸ“· DeepCluster: {len(photos)} photos ì…ë ¥")

        # Stage 2: ì „ì—­ ì„ë² ë”©
        features, valid_photos = self._extract_features(photos)
        if len(valid_photos) < 2:
            logger.warning("âš ï¸ usable photo ê°€ 2ì¥ ë¯¸ë§Œì…ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ë§ ë¶ˆê°€.")
            return [[p] for p in valid_photos]

        # Stage 2: k-NN ê·¸ë˜í”„ (ì „ì—­ ìœ ì‚¬ë„ ê¸°ì¤€)
        edges = self._build_candidate_edges(features, valid_photos)

        # Stage 3: ê¸°í•˜ ê²€ì¦ + edge í•„í„°ë§
        edges = self._filter_edges_by_geometry(edges, valid_photos)

        # Stage 4: Union-Find ë¡œ ì—°ê²°ìš”ì†Œ
        labels = self._connected_components(len(valid_photos), edges)

        # Stage 5: ë¼ë²¨ë³„ë¡œ ë¬¶ê³ , ì‹œê°„ ìˆœ ì •ë ¬
        clusters = self._build_clusters_from_labels(labels, valid_photos)

        logger.info(
            f"âœ… DeepCluster ì™„ë£Œ: {len(clusters)} clusters, "
            f"{sum(len(c) for c in clusters)} photos."
        )
        return clusters

    # ------------------------------------------------------------------
    # Stage 2: feature extraction
    # ------------------------------------------------------------------
    def _extract_features(
        self, photos: Sequence[PhotoMeta]
    ) -> Tuple[np.ndarray, List[PhotoMeta]]:
        feats: List[np.ndarray] = []
        valid_photos: List[PhotoMeta] = []

        for p in photos:
            path = Path(p.path)
            if not path.is_file():
                logger.warning(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
                continue
            vec = self.descriptor_extractor.extract_one(path)
            if vec is None:
                continue
            feats.append(vec)
            valid_photos.append(p)

        if not feats:
            return np.empty((0, 0), dtype=np.float32), []

        features_array = np.stack(feats, axis=0)
        logger.info(f"ğŸ“Š feature shape: {features_array.shape}")
        return features_array, valid_photos

    # ------------------------------------------------------------------
    # Stage 2: k-NN graph construction
    # ------------------------------------------------------------------
    def _build_candidate_edges(
        self,
        features: np.ndarray,
        photos: List[PhotoMeta],
    ) -> List[Tuple[int, int]]:
        n, d = features.shape
        if n == 0:
            return []

        k = min(max(2, self.knn_k), n)
        logger.info(f"ğŸ”— k-NN graph êµ¬ì„± (n={n}, d={d}, k={k})")

        nn = NearestNeighbors(n_neighbors=k, metric="cosine")
        nn.fit(features)
        distances, indices = nn.kneighbors(features)

        edges: List[Tuple[int, int]] = []

        for i in range(n):
            # indices[i][0] == ìê¸° ìì‹ 
            for dist, j in zip(distances[i][1:], indices[i][1:]):
                sim = 1.0 - float(dist)
                if sim < self.similarity_threshold:
                    continue
                # ì•„ì§ ê¸°í•˜ ê²€ì¦ì€ í•˜ì§€ ì•Šê³ , í›„ë³´ë¡œë§Œ ì €ì¥ (Stage 3ì—ì„œ í•„í„°ë§)
                if i < j:
                    edges.append((i, j))

        logger.info(f"ğŸ” ì „ì—­ ì„ë² ë”© ê¸°ì¤€ í›„ë³´ edge ìˆ˜: {len(edges)}")
        return edges

    # ------------------------------------------------------------------
    # Stage 3: geometric verification
    # ------------------------------------------------------------------
    def _filter_edges_by_geometry(
        self,
        edges: List[Tuple[int, int]],
        photos: List[PhotoMeta],
    ) -> List[Tuple[int, int]]:
        if not edges:
            return []

        logger.info("ğŸ§® SIFT + RANSAC ê¸°í•˜ ê²€ì¦ ì‹œì‘")
        kept: List[Tuple[int, int]] = []

        for (i, j) in edges:
            path_i = Path(photos[i].path)
            path_j = Path(photos[j].path)
            score_geo = self.geo_matcher.geo_score(path_i, path_j)
            if score_geo >= self.geo_threshold:
                kept.append((i, j))

        logger.info(
            f"ğŸ“Œ ê¸°í•˜ ê²€ì¦ í†µê³¼ edge ìˆ˜: {len(kept)} "
            f"(ì›ë˜ {len(edges)} ê°œ ì¤‘)"
        )
        return kept

    # ------------------------------------------------------------------
    # Stage 4: connected components
    # ------------------------------------------------------------------
    def _connected_components(
        self,
        n: int,
        edges: List[Tuple[int, int]],
    ) -> List[int]:
        if n == 0:
            return []

        if not edges:
            # edgeê°€ ì—†ìœ¼ë©´ ê°ì singleton cluster
            return list(range(n))

        uf = UnionFind(n)
        for i, j in edges:
            uf.union(i, j)
        labels = uf.to_labels()
        return labels

    # ------------------------------------------------------------------
    # Stage 5: build clusters + sort by time
    # ------------------------------------------------------------------
    def _build_clusters_from_labels(
        self,
        labels: List[int],
        photos: List[PhotoMeta],
    ) -> List[List[PhotoMeta]]:
        label_to_items: Dict[int, List[PhotoMeta]] = {}
        for idx, lbl in enumerate(labels):
            label_to_items.setdefault(lbl, []).append(photos[idx])

        clusters: List[List[PhotoMeta]] = []
        for lbl, items in label_to_items.items():
            # min_cluster_size ë³´ë‹¤ ì‘ì€ cluster ëŠ” ì¼ë‹¨ í¬í•¨ì€ í•˜ë˜,
            # í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ í•„í„°ë§í•  ìˆ˜ ìˆìŒ.
            cluster = sorted(
                items,
                key=lambda p: (p.timestamp or datetime.min, str(p.id)),
            )
            clusters.append(cluster)

        # í´ëŸ¬ìŠ¤í„° í¬ê¸° í° ìˆœìœ¼ë¡œ ì •ë ¬ (optional)
        clusters.sort(key=lambda c: len(c), reverse=True)
        return clusters
    
    def condition(self, c):
        return True