import logging
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import numpy as np
from domain.photometa import PhotoMeta
from PIL import Image

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)


class GlobalDescriptorExtractor:
    """
    ì „ì—­ ì„ë² ë”© ì¶”ì¶œê¸° (Stage 2).
    - ê¸°ë³¸ êµ¬í˜„ì€ CLIP(OpenCLIP ViT-B/32) ê¸°ë°˜
    - í”„ë¡œì íŠ¸ ìƒí™©ì— ë”°ë¼ place-recognition ì „ìš© ëª¨ë¸ë¡œ ë°”ê¾¸ê¸° ì‰¬ìš´ êµ¬ì¡°
    """

    def __init__(
        self,
        model_name: str = "ViT-B-32",
        pretrained: str = "openai",
        device: Optional[str] = None,
        image_size: int = 224,
    ) -> None:
        import open_clip
        import torch

        # device ì„ íƒ (mps -> cuda -> cpu)
        if device is not None:
            self.device = torch.device(device)
        else:
            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                self.device = torch.device("mps")
            elif torch.cuda.is_available():
                self.device = torch.device("cuda")
            else:
                self.device = torch.device("cpu")
        logger.info(f"ğŸ”§ Global descriptor device: {self.device}")

        self.model, _, preprocess = open_clip.create_model_and_transforms(
            model_name, pretrained=pretrained
        )
        self.model.to(self.device)
        self.model.eval()
        self.preprocess = preprocess
        self.image_size = image_size

    def extract_one(self, image_path: Path) -> Optional[np.ndarray]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ L2-normalized descriptor ë°˜í™˜.
        ì‹¤íŒ¨í•˜ë©´ None.
        """
        import torch

        try:
            img = Image.open(image_path).convert("RGB")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to open image {image_path}: {e}")
            return None

        with torch.no_grad():
            image_input = self.preprocess(img).unsqueeze(0).to(self.device)
            features = self.model.encode_image(image_input)
            features = features / features.norm(dim=-1, keepdim=True)
            feat_np: np.ndarray = features.cpu().numpy().flatten().astype(np.float32)
            return feat_np