{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# Fix module search path to allow unpickling of app.common or common classes\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "app_dir = os.path.join(project_root, \"app\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "if app_dir not in sys.path:\n",
    "    sys.path.append(app_dir)\n",
    "\n",
    "try:\n",
    "    from app.common.models import PhotoMeta\n",
    "except ImportError:\n",
    "    try:\n",
    "        from common.models import PhotoMeta\n",
    "    except ImportError:\n",
    "        # Fallback if running outside of app context and modules not found\n",
    "        from dataclasses import dataclass\n",
    "        @dataclass\n",
    "        class PhotoMeta:\n",
    "            path: str\n",
    "            lat: Optional[float] = None\n",
    "            lon: Optional[float] = None\n",
    "            timestamp: Optional[float] = None\n",
    "\n",
    "def load_dataset(path: str) -> dict:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/aohus/Workspaces/github/job-report-creator/cluster-backend/experiment/optimize_features/features/dataset_cache_vertex_masking.pkl\"\n",
    "data = load_dataset(dataset_path)\n",
    "photos = data['photos']\n",
    "features = data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similarity_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def find_similar_photos(target_idx: int, photos: list, features: np.ndarray, top_k: int = 5):\n",
    "    target_vector = features[target_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(target_vector, features)[0]\n",
    "    \n",
    "    # Get top K indices (excluding itself)\n",
    "    top_indices = similarities.argsort()[::-1][:top_k+1]\n",
    "    \n",
    "    print(f\"Target Photo: {photos[target_idx].path}\")\n",
    "    \n",
    "    # Display target photo\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    try:\n",
    "        plt.imshow(Image.open(photos[target_idx].path))\n",
    "        plt.title(\"Target Photo\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load target image: {e}\")\n",
    "    \n",
    "    print(f\"\\nTop {top_k} Similar Photos:\")\n",
    "    count = 0\n",
    "    for idx in top_indices:\n",
    "        if idx == target_idx:\n",
    "            continue\n",
    "            \n",
    "        score = similarities[idx]\n",
    "        photo_path = photos[idx].path\n",
    "        print(f\"Score: {score:.4f} - {photo_path}\")\n",
    "        \n",
    "        plt.figure(figsize=(5, 5))\n",
    "        try:\n",
    "            plt.imshow(Image.open(photo_path))\n",
    "            plt.title(f\"Score: {score:.4f}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {photo_path}: {e}\")\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top_k:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similarity_usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage: Find similar photos for the first photo in the dataset\n",
    "target_index = 0 # Change this index to select a different photo\n",
    "if len(photos) > target_index:\n",
    "    find_similar_photos(target_index, photos, features, top_k=5)\n",
    "else:\n",
    "    print(\"Dataset is empty or index out of bounds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to path to allow importing clusters.py\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "try:\n",
    "    from clusters import TunableHybridCluster\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing TunableHybridCluster: {e}\")\n",
    "    print(\"Ensure clusters.py is in the same directory and app.common.models is accessible.\")\n",
    "\n",
    "def analyze_clustering_results(photos, features):\n",
    "    print(\"Initializing Clustering with TunableHybridCluster...\")\n",
    "    \n",
    "    # Default params matching clusters.py defaults or reasonable values\n",
    "    params = {\n",
    "        'max_gps_tol': 40.0,\n",
    "        'loose_thresh': 0.5,\n",
    "        'min_cluster_size': 2,\n",
    "        'min_samples': 2\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        clusterer = TunableHybridCluster(params)\n",
    "        labels = clusterer.run_clustering(photos, features)\n",
    "    except Exception as e:\n",
    "        print(f\"Clustering failed: {e}\")\n",
    "        return\n",
    "        \n",
    "    unique_labels = set(labels)\n",
    "    # Exclude noise (-1) from count\n",
    "    clusters = [l for l in unique_labels if l != -1]\n",
    "    n_clusters = len(clusters)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    print(f\"\\n--- Clustering Report ---\")\n",
    "    print(f\"Total Photos: {len(photos)}\")\n",
    "    print(f\"Clusters Found: {n_clusters}\")\n",
    "    print(f\"Noise Points: {n_noise}\")\n",
    "    \n",
    "    # Visualization\n",
    "    # Group indices by label\n",
    "    cluster_dict = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in cluster_dict:\n",
    "            cluster_dict[label] = []\n",
    "        cluster_dict[label].append(idx)\n",
    "    \n",
    "    # Sort clusters by size (descending)\n",
    "    sorted_labels = sorted(clusters, key=lambda l: len(cluster_dict[l]), reverse=True)\n",
    "    \n",
    "    # Show top 5 clusters\n",
    "    for i, label in enumerate(sorted_labels[:5]):\n",
    "        indices = cluster_dict[label]\n",
    "        print(f\"\\nCluster ID {label}: {len(indices)} photos\")\n",
    "        \n",
    "        # Show first 5 images of the cluster\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for j, idx in enumerate(indices[:5]):\n",
    "            photo = photos[idx]\n",
    "            plt.subplot(1, 5, j+1)\n",
    "            try:\n",
    "                img = Image.open(photo.path)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"{os.path.basename(photo.path)}\", fontsize=8)\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if n_noise > 0:\n",
    "        print(f\"\\nNoise Points (Sample):\")\n",
    "        indices = cluster_dict[-1]\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for j, idx in enumerate(indices[:5]):\n",
    "            photo = photos[idx]\n",
    "            plt.subplot(1, 5, j+1)\n",
    "            try:\n",
    "                img = Image.open(photo.path)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Noise: {os.path.basename(photo.path)}\", fontsize=8)\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute clustering analysis\n",
    "if 'photos' in locals() and 'features' in locals():\n",
    "    analyze_clustering_results(photos, features)\n",
    "else:\n",
    "    print(\"Photos or features not loaded. Run previous cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}